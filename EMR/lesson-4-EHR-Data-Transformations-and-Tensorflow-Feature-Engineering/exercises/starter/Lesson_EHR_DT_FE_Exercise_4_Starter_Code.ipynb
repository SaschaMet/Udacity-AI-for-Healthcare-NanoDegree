{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise  L3 - 4:  Build Embedding Categorical Feature with TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "- Build a 10 dimension embedding feature for the PRINCIPAL_DIAGNOSIS_CODE field\n",
    "- Here is the link to the Tensorflow Embedding column documentation -https://www.tensorflow.org/api_docs/python/tf/feature_column/embedding_column\n",
    "- Some functions provided below to assist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_line_df = pd.read_csv(\"./data/SYNTHETIC_EHR_DATASET.csv\")\n",
    "cat_example_df = ehr_line_df[['ENCOUNTER_ID', 'PRINCIPAL_DIAGNOSIS_CODE', 'LABEL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from https://www.tensorflow.org/tutorials/structured_data/feature_columns\n",
    "def df_to_dataset(df, predictor,  batch_size=32):\n",
    "    df = df.copy()\n",
    "    labels = df.pop(predictor)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(df))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "PREDICTOR_FIELD = 'LABEL'\n",
    "categorical_tf_ds = df_to_dataset(cat_example_df, PREDICTOR_FIELD, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocab for categorical features\n",
    "def write_vocabulary_file(vocab_list, field_name, default_value, vocab_dir='./vocab/'):\n",
    "    output_file_path = os.path.join(vocab_dir, str(field_name) + \"_vocab.txt\")\n",
    "    # put default value in first row as TF requires\n",
    "    vocab_list = np.insert(vocab_list, 0, default_value, axis=0) \n",
    "    df = pd.DataFrame(vocab_list).to_csv(output_file_path, index=None, header=None)\n",
    "    return output_file_path\n",
    "\n",
    "def build_vocab_files(df, categorical_column_list, default_value='00'):\n",
    "    vocab_files_list = []\n",
    "    for c in categorical_column_list:\n",
    "        v_file = write_vocabulary_file(df[c].unique(), c, default_value)\n",
    "        vocab_files_list.append(v_file)\n",
    "    return vocab_files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_udacity_hc_env",
   "language": "python",
   "name": "test_udacity_hc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
